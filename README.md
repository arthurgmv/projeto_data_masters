# üî• Data Masters ‚Äì Pipeline de Engenharia de Dados End-to-End

<p align="center">
  <strong>Choose your language:</strong><br>
  <a href="README.eng.md">üá∫üá∏ English</a> |
  <a href="README.md">üáßüá∑ Portugu√™s</a> |
</p>

---

![Status](https://img.shields.io/badge/Status-Completed-success?style=for-the-badge&logo=git&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.12-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Spark](https://img.shields.io/badge/Apache%20Spark-3.5.0-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Tests](https://img.shields.io/badge/Pytest-Passing-0A9EDC?style=for-the-badge&logo=pytest&logoColor=white)

Este projeto simula um <b>ambiente corporativo real de Engenharia de Dados</b>, implementando um <b>pipeline End-to-End completo</b>, baseado na arquitetura <b>Lakehouse / Medallion</b>.
O objetivo principal foi construir uma <b>infraestrutura resiliente e independente de sistema operacional</b>, resolvendo problemas cl√°ssicos de compatibilidade entre <b>Apache Spark e Windows</b> por meio de <b>containeriza√ß√£o total com Docker</b>.
Al√©m disso, o projeto possui forte foco em <b>Qualidade de Dados e conformidade com a LGPD</b>.

## üìÖ Ciclo de Vida do Projeto ‚Äì Fases de Desenvolvimento

O projeto seguiu um ciclo estruturado para garantir que a <b>estabilidade da infraestrutura</b> e a <b>qualidade dos dados</b> fossem validadas antes da execu√ß√£o da l√≥gica de neg√≥cio.

```mermaid
graph TD
    classDef study fill:#636e72,stroke:#fff,stroke-width:2px,color:#fff;
    classDef planning fill:#2d3436,stroke:#fff,stroke-width:2px,color:#fff;
    classDef infra fill:#0984e3,stroke:#fff,stroke-width:2px,color:#fff;
    classDef code fill:#00b894,stroke:#fff,stroke-width:2px,color:#fff;
    classDef deliver fill:#fdcb6e,stroke:#333,stroke-width:2px,color:#333;

    subgraph Timeline [Ciclo de Vida do Projeto]
        direction TB
        Z(0. Fundamentos Conceituais & Estudo do Dom√≠nio):::study --> A(1. Planejamento & Arquitetura):::planning
        A --> B(2. Infraestrutura Docker & MinIO):::infra
        B --> C(3. Ingest√£o ‚Äì Camada Bronze):::code
        C --> D(4. Framework de Testes & Qualidade de Dados):::code
        D --> E(5. Processamento & LGPD ‚Äì Camada Silver):::code
        E --> F(6. Agrega√ß√£o de KPIs ‚Äì Camada Gold):::code
        F --> G(7. Documenta√ß√£o & Entrega):::deliver
    end
```

## üìñ Contexto Conceitual

> ‚ÄúA engenharia de dados √© um conjunto de opera√ß√µes destinadas a criar interfaces e mecanismos para o fluxo e o acesso √† informa√ß√£o.  
> S√£o necess√°rios especialistas dedicados ‚Äî engenheiros de dados ‚Äî para manter os dados dispon√≠veis e utiliz√°veis por outros.  
> Em suma, os engenheiros de dados criam e operam a infraestrutura de dados da organiza√ß√£o, preparando-a para an√°lises posteriores por analistas e cientistas de dados.‚Äù
>
> ‚Äî **AltexSoft**, *Data Engineering Concepts, Processes, and Tools* (citado em *Fundamentos de Engenharia de Dados*, O‚ÄôReilly)

Este projeto foi concebido para refletir essa defini√ß√£o na pr√°tica, com foco em **disponibilidade dos dados**, **confiabilidade**, **qualidade** e **prontid√£o para consumo anal√≠tico**.



## üèóÔ∏è Vis√£o Geral do Pipeline de Dados (Arquitetura)

Abaixo est√° a vis√£o abstrata do fluxo de dados. O pipeline segue a <b>Arquitetura Medallion</b>, onde os dados s√£o refinados progressivamente a cada camada.

---
```mermaid
flowchart LR
    Generator(["Gerador de Dados (Python Faker)"])

    subgraph Lakehouse ["Data Lakehouse - MinIO"]
        direction LR
        Bronze[("Camada Bronze (JSON Bruto)")]
        Silver[("Camada Silver (Parquet Confi√°vel)")]
        Gold[("Camada Gold (KPIs Refinados)")]
    end

    subgraph Processing ["Cluster Spark - Docker"]
        direction LR
        Ingestor[("Ingest√£o")]
        Transformer[("Motor de Transforma√ß√£o (Qualidade + LGPD)")]
        Aggregator[("Agrega√ß√£o de Neg√≥cio")]
    end

    Generator --> Ingestor
    Ingestor -->|Escrita Bruta| Bronze
    
    Bronze -->|Leitura| Transformer
    Transformer -->|Escrita Limpa| Silver
    
    Silver -->|Leitura| Aggregator
    Aggregator -->|Escrita Agregada| Gold
```
## üèõÔ∏è Contexto Arquitetural e Justificativa

A ado√ß√£o da arquitetura **Lakehouse / Medallion** neste projeto **n√£o foi arbitr√°ria**. Ela decorre de um estudo comparativo entre arquiteturas modernas de dados, fundamentado nos crit√©rios de **custo, complexidade operacional e amplitude de casos de uso**, conforme discutido por **James Serra** em *Decifrando Arquiteturas de Dados* (O‚ÄôReilly), al√©m de conceitos consolidados em *Fundamentos de Engenharia de Dados* (O‚ÄôReilly).

### ‚ùå Por que n√£o um Data Warehouse tradicional?
Embora Data Warehouses ofere√ßam **baixa lat√™ncia e forte consist√™ncia**, apresentam **alto custo de licenciamento e manuten√ß√£o**, al√©m de **limita√ß√µes para dados semiestruturados, n√£o estruturados e workloads anal√≠ticos avan√ßados**, como Machine Learning e Data Science.

### ‚ùå Por que n√£o apenas um Data Lake?
Apesar do **baixo custo de armazenamento em objetos**, Data Lakes puros tendem a sofrer com **falta de governan√ßa, sem√¢ntica e controle de qualidade**, levando ao conhecido fen√¥meno de *Data Swamp*, o que dificulta o consumo anal√≠tico confi√°vel.

### ‚ùå Por que n√£o Data Mesh ou Data Fabric?
Arquiteturas como **Data Mesh** e **Data Fabric** s√£o conceitualmente robustas, por√©m exigem **alta maturidade organizacional**, **dom√≠nios bem definidos**, **times descentralizados** e um conjunto amplo de habilidades t√©cnicas e culturais ‚Äî classificados por Serra como arquiteturas de **alta complexidade operacional**. Esses requisitos extrapolariam o escopo e os objetivos deste projeto.

---

### üèÜ A Escolha: Lakehouse com Arquitetura Medallion

A arquitetura **Lakehouse**, estruturada no padr√£o **Medallion (Bronze, Silver e Gold)**, foi selecionada por representar o **melhor equil√≠brio t√©cnico** para o cen√°rio corporativo simulado neste case:

1. **Custo-Efici√™ncia:** Uso de armazenamento em objetos (MinIO/S3-compatible) com baixo custo e alta escalabilidade.
2. **Versatilidade Anal√≠tica:** Suporte tanto a BI tradicional quanto a workloads de Ci√™ncia de Dados e Machine Learning.
3. **Governan√ßa Pragm√°tica:** Organiza√ß√£o em camadas promove qualidade, rastreabilidade e evolu√ß√£o progressiva dos dados, sem a rigidez excessiva de um Data Warehouse legado.

Essa abordagem reflete pr√°ticas amplamente adotadas em ambientes corporativos modernos, conciliando **robustez arquitetural**, **simplicidade operacional** e **ader√™ncia aos objetivos do projeto**.

> *Embora a implementa√ß√£o tenha sido consolidada em um curto per√≠odo, este projeto √© resultado de mais de um ano de estudo cont√≠nuo e prepara√ß√£o em Engenharia de Dados, refletindo decis√µes arquiteturais conscientes e fundamentadas.*

---

## üß† Engenharia: Decis√µes Arquiteturais e Trade-offs

Este projeto foi desenhado simulando um cen√°rio real, onde cada escolha t√©cnica visou resolver um problema espec√≠fico de neg√≥cio ou infraestrutura.

| Decis√£o | O Problema | A Solu√ß√£o Adotada | Por que n√£o a alternativa? |
| :--- | :--- | :--- | :--- |
| **Containeriza√ß√£o Total** | O ambiente Windows frequentemente conflita com bibliotecas Hadoop/Spark nativas do Linux (`winutils.exe`). | **Docker & Docker Compose.** Criamos um ambiente Linux isolado que roda o Spark de forma nativa. | Rodar localmente no Windows traria instabilidade e dificultaria a reprodu√ß√£o do projeto em outras m√°quinas ("Works on my machine"). |
| **MinIO (S3)** | Necessidade de simular um Data Lake em nuvem sem gerar custos de AWS/Azure. | **MinIO Server.** Ele utiliza exatamente a mesma API do Amazon S3 (`boto3` / `s3a://`). | Usar o sistema de arquivos local (`file://`) n√£o prepararia o c√≥digo para uma migra√ß√£o real para a nuvem (Cloud Native). |
| **Orquestra√ß√£o Customizada** | Pipelines de dados precisam de tratamento de erro, logs e depend√™ncia entre tarefas. | **Script Python (`pipeline.py`).** Controle total do fluxo de execu√ß√£o com `try/catch` e logs estruturados. | **Por que n√£o Airflow neste momento?** Para este escopo, subir um cluster Airflow (Webserver + Scheduler + Worker) adicionaria um *overhead* de infraestrutura desnecess√°rio. A l√≥gica atual √© facilmente port√°vel para uma DAG no futuro. |
| **Formato Parquet** | Armazenamento de Big Data requer compress√£o e leitura eficiente. | **Apache Parquet (Snappy).** Padr√£o de mercado para Analytics. | CSVs n√£o mant√™m schema (tipagem) e s√£o lentos para leitura. O Parquet garante performance na camada Silver/Gold. |

---
## üîÆ Roadmap e Melhorias Futuras

O desenvolvimento de software √© iterativo. Abaixo, listo as evolu√ß√µes planejadas para levar este projeto ao pr√≥ximo n√≠vel de maturidade (Enterprise Level).

* [ ] **Migra√ß√£o para Delta Lake:**
    * *Objetivo:* Implementar transa√ß√µes ACID e *Time Travel*.
    * *Contexto:* Atualmente utilizo **Parquet** padr√£o para demonstrar o dom√≠nio da manipula√ß√£o de arquivos brutos no Spark, mas a evolu√ß√£o natural do Lakehouse √© o formato Delta para garantir *Schema Enforcement*.
* [ ] **Orquestra√ß√£o com Airflow:**
    * *Objetivo:* Monitoramento visual, retries autom√°ticos e backfilling.
    * *Contexto:* A l√≥gica de orquestra√ß√£o j√° est√° desacoplada no script `src/pipeline.py`, o que facilita a migra√ß√£o para `PythonOperator` ou `SparkSubmitOperator` dentro de uma DAG do Airflow.
* [ ] **CI/CD (GitHub Actions):**
    * *Objetivo:* Automatizar a execu√ß√£o dos testes (`pytest`) a cada Push ou Pull Request.
* [ ] **Dashboarding:**
    * *Objetivo:* Conectar o Power BI ou Metabase diretamente ao MinIO (via Thrift Server ou Presto) para consumir a camada Gold.

---

## üõ°Ô∏è Diferenciais do Projeto
### 1. Qualidade de Dados como Prioridade

Diferente de pipelines tradicionais que apenas movimentam dados, este projeto imp√µe port√µes expl√≠citos de qualidade.

Testes Unit√°rios: l√≥gica de transforma√ß√£o validada com pytest

Valida√ß√£o em Runtime: valores cr√≠ticos nulos ou negativos s√£o bloqueados antes da promo√ß√£o para Silver

### 2. Privacidade & Conformidade com LGPD

Implementa√ß√£o pr√°tica do conceito Privacy by Design.

Camada Bronze: dados brutos e sens√≠veis

Camada Silver: dados anonimizados

Exemplos:

CPF ‚Üí *** *** ***-XX

Cart√£o de Cr√©dito ‚Üí **** **** **** 1234

### 3. Infraestrutura Totalmente Containerizada

O mesmo pipeline executa de forma id√™ntica em:

Windows

Linux

Ambientes Cloud

Eliminando o cl√°ssico problema: <b>‚Äúna minha m√°quina funciona‚Äù</b>.



## üöÄ Como Executar o Projeto
### Pr√©-requisitos

Docker Desktop (em execu√ß√£o)

Git

### Clonar o reposit√≥rio
```
git clone https://github.com/arthurgmv/projeto_data_masters.git
cd projeto_data_masters
```
### Configurar Vari√°veis de Ambiente (Passo Crucial) ‚ö†Ô∏è
O projeto utiliza vari√°veis de ambiente para garantir a seguran√ßa das credenciais. Voc√™ deve criar um arquivo `.env` baseado no exemplo fornecido.
```
# Linux / Mac
cp .env.example .env

<<<<<<< HEAD
### Start the infrastructure
=======
# Windows (Prompt de Comando / PowerShell)
copy .env.example .env
```

### Subir a infraestrutura
>>>>>>> d297535b07ef79b40708cca787d5e5e39388e51c
```
docker-compose up -d
```
### Instalar depend√™ncias no cluster Spark
```
docker exec spark_master pip install boto3 python-dotenv pytest faker colorama pyspark
```
### Executar testes de qualidade de dados
```
docker exec spark_master pytest -v /app/tests/
```
### Executar o pipeline completo
```
docker exec spark_master python3 src/pipeline.py
```
## üìä Acesso aos Dados

<b>Console do MinIO (Data Lake)</b>
http://localhost:9001

<b>Usu√°rio</b>: admin

<b>Senha</b>: minioadmin

<b>Spark Master UI</b>
http://localhost:8080

## üìû Contato

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Arthur%20Gabriel-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)]([https://www.linkedin.com/in/arthur-gabriel-de-menezes-viana-4b0690201/](https://www.linkedin.com/in/arthur-gabriel-de-menezes-viana-1223a6239/))
